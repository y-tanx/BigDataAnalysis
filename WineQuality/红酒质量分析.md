# 葡萄酒质量评估模型

大数据分析的过程：

![image-20241215142703404](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/202412151703899.png)

## 业务理解

根据葡萄牙北部的红、白绿葡萄酒“Vinho Verde”样品相关的数据集，为红、白葡萄酒“Vinho Verde”建立基于物理化学测试的质量评估模型，这种模型有助于支持酿酒师的葡萄酒品尝评估并提高葡萄酒产量

## 数据理解

### 数据集概述

数据集来源：http://www.vinhoverde.pt/en/，由于隐私和后勤问题，只有理化性质（如酒精、柠檬酸）和 感官变量（颜色、质量评分）可用（没有关于葡萄类型、葡萄酒品牌、葡萄酒销售价格等数据），因此只能基于物理化学测试结果来建立质量评估模型。共有13个变量，其中有11个变量是理化性质，其它2个变量是颜色和质量：

|       变量名称       |  角色   |    类型     |             描述             | 缺失值 |
| :------------------: | :-----: | :---------: | :--------------------------: | :----: |
|    fixed_acidity     | Feature | Continuous  |           固定酸度           |   no   |
|   volatile_acidity   | Feature | Continuous  |          挥发性酸度          |   no   |
|     citric_acid      | Feature | Continuous  |            柠檬酸            |   no   |
|    residual_sugar    | Feature | Continuous  |             残糖             |   no   |
|      chlorides       | Feature | Continuous  |            氯化物            |   no   |
| free_sulfur_dioxide  | Feature | Continuous  |         游离二氧化硫         |   no   |
| total_sulfur_dioxide | Feature | Continuous  |          总二氧化硫          |   no   |
|       density        | Feature | Continuous  |             密度             |   no   |
|          pH          | Feature | Continuous  |            酸碱度            |   no   |
|      sulphates       | Feature | Continuous  |            硫酸盐            |   no   |
|       alcohol        | Feature | Continuous  |             酒精             |   no   |
|       quality        | Target  |   Integer   | 质量(score between 0 and 10) |   no   |
|        color         |  Other  | Categorical |      颜色(red or white)      |   no   |

有2个数据集：

+ `winequality-white.csv`：白葡萄酒的理化性质和质量，每一行都是一个白葡萄酒的 11种理化性质的值 和 质量标签。共有4898个白葡萄酒样本
+ `winequality-red.csv`：红葡萄酒的理化性质和质量，每一行都是一个红葡萄酒的 11中理化性质的值 和 质量标签。共有1599个红葡萄酒样本

### 数据集特征

这是描述分析的内容

**红、白葡萄酒理化性质**：

![image-20241217120748536](./红酒质量分析.assets/image-20241217120748536.png)

**红葡萄酒的质量直方分布图：**

![image-20241215181844511](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/image-20241215181844511.png)

**白葡萄酒的质量直方分布图**：

![image-20241215181830685](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/image-20241215181830685.png)

由图中可以分析出**样本并不平衡**：普通的葡萄酒（5~7分）更多，而劣质（1 ~ 4分）或优质（8 ~ 10分）的葡萄酒相对很少。而且**不确定是否所有输入变量都与质量相关**，因此需要提取出至多7个与质量相关度很高的理化性质作为接下来分析的变量

## 数据准备

这包括数据抽样和过滤、数据标准化和归一化、数据清洗，最终使数据变为可以直接输入到模型的工作集

+ **数据抽样和过滤**：

  + **过采样**：由于数据集不平衡，可以考虑进行过采样。SMOTE方法在少数类样本之间插值生成新的样本，它不仅复制少数类样本，还生成新的合成样本，从而减少了过拟合的风险，因此选择SMOTE方法进行过采样。

    !参考：[处理不平衡数据集的关键技术：过采样和欠采样](https://blog.csdn.net/qq_35240081/article/details/139222470)

  + **变量筛选**：由数据理解部分得出的结论，需要筛选出至多7个与质量相关的变量

+ **数据标准化和归一化**：由于各个理化性质的量纲不同，对后续分析会产生影响，因此需要对数据进行标准化或归一化

+ **数据清洗**：数据集中没有缺失的属性，没有语法语义上的错误，因此不需要进行数据清洗

### 变量筛选

由数据理解步骤，首先需要计算各个属性与质量的皮尔森相关系数，选取相关系数最大的前7个属性作为接下来研究的变量

使用Spark分别计算红、白葡萄酒中各个属性与质量的皮尔森相关系数，核心代码：

```java
// 使用Correlation.corr方法计算各个属性与质量之间的皮尔森相关系数
Map<String, Double> correlationMap = new HashMap<String, Double>(); // 存储各个属性与质量之间的皮尔森相关系数
for(String feature : features) {
    Dataset<Row> correlationDS = df.select(feature, "quality");  // 提取属性名 和 quality列

    // 使用VectorAssembler.transform，将要计算相关系数的两列合并为一个向量，如1.2, 6合并为[1.2, 6]
    VectorAssembler vectorAssembler = new VectorAssembler().setInputCols(new String[]{feature, "quality"}).setOutputCol("combination"); // 工具类，指定输入两个列的列名和输出的列名
    Dataset<Row> combinedDS = vectorAssembler.transform(correlationDS);     // combinedDS中包含了feature、quality、[feature, quality]

    // 使用Correlation.corr方法计算feature与quality的皮尔森相关系数
    Row correlationRow = Correlation.corr(combinedDS, "combination", "pearson").head();   // 指定对"combination这个向量计算pearson相关系数
    Matrix correlationMatrix = correlationRow.getAs(0); // 获取相关性矩阵
    double correlation = correlationMatrix.apply(0, 1);   // 提取(0, 1)的指，即feature与quality的相关系数

    // 将相关系数保存到hashMap中
    correlationMap.put(feature, correlation);
}
```

选择`correlationMap`中前7个相关系数绝对值最大的属性，将它们作为接下来研究的变量，构造包含这7个属性+质量的新CSV文件

**红葡萄酒**

|         名称         | 与quality的相关系数  |
| :------------------: | :------------------: |
|      chlorides       | -0.12890655993005298 |
|       alcohol        |  0.4761663240011388  |
|       density        | -0.17491922778334934 |
| free sulfur dioxide  | -0.05065605724427631 |
|    fixed acidity     | 0.12405164911322412  |
|     citric acid      | 0.22637251431804165  |
|          pH          | -0.05773139120538233 |
| total sulfur dioxide | -0.18510028892653863 |
|   volatile acidity   | -0.3905577802640098  |
|    residual sugar    | 0.013731637340066436 |
|      sulphates       | 0.25139707906926184  |

选择的7个属性: [`alcohol`, `volatile acidity`, `sulphates`, `citric acid`, `total sulfur dioxide`, `density`, `chlorides`]

**白葡萄酒**

|         名称         |  与quality的相关系数  |
| :------------------: | :-------------------: |
|      chlorides       | -0.20993441094676413  |
|       alcohol        |  0.43557471546138643  |
|       density        | -0.30712331273473903  |
| free sulfur dioxide  | 0.008158067123436388  |
|    fixed acidity     | -0.11366283071302036  |
|     citric acid      | -0.009209090883975465 |
|          pH          |  0.0994272457366663   |
| total sulfur dioxide |  -0.1747372175970664  |
|   volatile acidity   | -0.19472296892114058  |
|    residual sugar    | -0.09757682889469596  |
|      sulphates       | 0.053677877132793476  |

选择的7个属性： [`alcohol`, `density`, `chlorides`, `volatile acidity`, `total sulfur dioxide`, `fixed acidity`, `pH`]

### 过采样SMOTE

由红、白葡萄酒的质量分布图可知，数据集中质量的分布是很不平衡的，呈现为一般葡萄酒的样本数较多（5 ~ 7），劣质（1 ~ 4）和优质（8 ~ 10）葡萄酒的样本较少。样本不平衡会使得我们的分类模型存在很严重的偏向性。由于数据集的样本量不是很多，则采用过采样的方法，增加小类的样本数。这里采用SMOTE方法进行过采样

!参考：https://www.cnblogs.com/QuincyYi/p/17756932.html

**红葡萄酒**

```python
smote = SMOTE(sampling_strategy={3: 100, 4: 150, 7: 300, 8: 120}, k_neighbors=5, random_state=42)
```

SMOTE处理后的数据集类别分布:
quality
5    681
6    638
7    300
4    150
8    120
3    100
Name: count, dtype: int64

**白葡萄酒**

```python
smote = SMOTE(sampling_strategy={3: 100, 4: 300, 8: 300, 9: 50}, k_neighbors=3, random_state=42)
```

SMOTE处理后的数据集类别分布:
quality
6    2198
5    1457
7     880
8     300
4     300
3     100
9      50
Name: count, dtype: int64

### 标准化

准备选择SVM作为分类器，为了消除量纲对后续分析的影响，需要进行标准化：$X_{std} = \frac{X-μ}{\sigma}$

*Q*：为什么选择标准化？

*A*：SVM 的核函数（尤其是 RBF 核）对输入特征的大小敏感。特征分布的不同尺度会导致某些特征对分类的影响被放大或缩小，标准化可以平衡不同特征对模型的影响，因此是一个更好的选择

使用Spark的`StandardScaler`类对特征向量进行标准化，核心代码：

```java
// 使用StandardScaler对特征向量进行标准化
StandardScaler scaler = new StandardScaler()
        .setInputCol("originalFeatures")    // 输入的向量名为originalfeatures，即上一步合并出的向量
        .setOutputCol("standardFeatures")   // 输出的向量名为standardFeatures
        .setWithMean(true)
        .setWithStd(true);   // 将数据均值标准化为0，方差标准化为1

Dataset<Row> standardDS = scaler.fit(assembledDS).transform(assembledDS);

// 将标准化后的向量列拆解成单个属性列
Dataset<Row> resultDS = standardDS;
for(int i = 0; i < features.length; i++){
    resultDS = resultDS.drop(features[i]);  // 删除原始列
    String columnName = "`" + features[i] + "`";    // 属性名称中有空格,需要加上``
    // 从向量中分解出第i个属性的列
    int finalI = i;
    resultDS = resultDS.withColumn(columnName, functions.udf(
            (Vector v) -> v.toArray()[finalI], DataTypes.DoubleType
            ).apply(functions.col("standardFeatures")));
}
```

经过标准化后，各个属性列的数据的均值为0，方差为1

## 建模

### SVM分类器

#### 基本原理

**支持向量机** 是一种常用于分类和回归分析的机器学习算法。其核心思想是通过在高维空间中找到一个超平面，将不同类别的样本分开，使得类别间的间隔最大化。SVM 在处理二分类问题时，能有效地构建出决策边界。

在实验中，使用了 `org.apache.spark.ml.classification.LinearSVC` 类在 Spark 平台上实现了 L2-SVM 分类器，成功地实现了 L2-SVM 算法

**L2-SVM** 是一种在传统 SVM 基础上引入 L2 正则化的支持向量机方法。其主要目标是在进行分类时，通过惩罚过度复杂的模型（即减少模型的过拟合）来提高模型的泛化能力

L2-SVM 的**优化目标**为：
$$
\min_{w, b, \xi} \quad \frac{1}{2} \|w\|^2 + C \sum_{i=1}^{n} \xi_i
$$
其中：

- $w$ 是超平面的法向量
- $\|w\|$ 是$w$的 L2 范数。
- $C$是一个正则化参数，用来平衡间隔大小和分类误差的容忍度。
- $ξ_i$是松弛变量，允许一定的分类误差

L2-SVM的**约束条件**为：
$$
y_i (w \cdot x_i + b) \geq 1 - \xi_i, \quad \forall i
$$
其中：

+ $y_i\in\{-1, 1\}$为样本的类别标签
+ $x_i$为样本的特征向量
+ $b$是偏置项
+ $ξ_i$是松弛变量，允许一定的分类误差

#### One-vs-All

葡萄酒的质量标签分为10类（1~10），这是一个多分类的问题。在SVM模型中，需要使用One-vs-All策略将多分类问题转换为多个二分类问题，即为每个类别训练一个SVM分类器，这个分类器用于判断输入的样本是否属于该类别。对于一个样本，我们可以将其输入到所有SVM分类器中，最终的预测类别是 输出最大得分的分类器对应的类别

#### k折交叉验证

交叉验证是在机器学习建立模型和验证模型参数时常用的方法，一般被用于评估一个机器学习模型的表现

K折交叉验证 将初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。由于样本数据量不大，因此在SVM模型训练中，使用5折交叉验证来对模型进行评估

#### SVM分类器的实现

+ **对数据集的处理**
  + **特征向量和标签向量的构建**：Spark的` LinearSVC`类处理的是特征向量和标签向量，因此需要使用` VectorAssembler`类将各个属性列合并为一个向量，并抽离出标签列
  + **根据One-vs-All策略处理标签向量**：根据One-vsAll策略，每次都只针对某一个类别进行二分类，因此需要在标签向量中将当前类别设置为1，其它类别全部设置为0。在Spark中，可以使用`WithColumn`创建出 二元标签向量：`binaryLabel`
+ **模型的训练**
  + **训练策略**：使用5折交叉验证，需要进行5轮训练，每轮训练中，以某个折为验证集，其它4个折为训练集。在Spark中，使用`LinearSVC`类 指定特征向量和标签向量的名称 并 设置参数，包括最大迭代次数、正则化系数、容忍度、
  + **参数的选择**：在训练过程中，注意到样本少的类别出现了过拟合，而样本多的类别的准确率不高，因此需要对不同类别的SVM分类器设置不同参数，分别训练

核心代码：

```java
// k折交叉验证
for(int i = 0; i < k; ++i)
{
    fileWriter.write("验证集为第" + i + "个折\n");
    // 以第i个折为验证集，其它折为训练集
    Dataset<Row> validationSet = folds[i];

    // 合并训练集
    List<Row> emptyList = Collections.emptyList();
    Dataset<Row> trainSet = spark.createDataFrame(emptyList, data.schema());
    for(int j = 0; j < k; ++j)
    {
        if(j != i)
        {
            trainSet = trainSet.union(folds[j]);
        }
    }

    // SVM训练和验证，使用One-vs-All策略
    // 注意到, 数据集中对于一部分类别是没有样本的（比如red中1~2，9~10），而SVM分类器是二分类的，样本中必须出现两类，需要排除这样的情况
    for(int label = 1; label <= 10; label++)
    {
        // 对当前类别建立SVM二分类模型，将样本中质量为当前类别的设置为1，其它类别设置为0. 注意标签的类型要为Double
        Dataset<Row> binaryTrainSet = trainSet.withColumn("binaryLabel", trainSet.col("label").equalTo(label).cast(DataTypes.DoubleType));

        // 排除只有一个类别(0)的训练集
        long distinctLabels = binaryTrainSet.select("binaryLabel").distinct().count();
        if(distinctLabels == 1)
        {
            continue;
        }

        Dataset<Row> binaryValidationSet = validationSet.withColumn("binaryLabel", validationSet.col("label").equalTo(label).cast(DataTypes.DoubleType));

        // 训练SVM模型
        LinearSVC lsvc = new LinearSVC()
                .setLabelCol("binaryLabel") // 设置标签列
                .setFeaturesCol("features") // 设置特征列(Vector类型)
                .setMaxIter(50)            // 设置最大迭代次数
                .setRegParam(0.5);          // 设置正则化参数, 防止模型过拟合（可能需要调整）

        LinearSVCModel model = lsvc.fit(binaryTrainSet);

        // 预测验证集
        Dataset<Row> predictions = model.transform(binaryValidationSet);
        long correctPredictions = predictions.filter(
                predictions.col("binaryLabel").equalTo(predictions.col("prediction"))
        ).count();  // 预测正确的样本数
        long totalPredictions = predictions.count();

        // 计算当前SVM分类器的准确率
        double accuracy = correctPredictions * 1.0 / totalPredictions;
        accuracies.add(accuracy);
        fileWriter.write("类别" + label + " SVM分类器的准确率: " + accuracy + "\n");
    }
}
```

## 评估

### 红葡萄酒

#### SVM模型参数

类别3、4、8

+ 最大迭代次数：30
+ 正则化系数：0.01
+ 容忍度T：1e-3

类别7

+ 最大迭代次数：100
+ 正则化系数：0.1
+ 容忍度：1e-4

类别5、6

+ 最大迭代次数：400
+ 正则化系数：0.8
+ 容忍度：1e-4

#### 准确率

类别3的平均准确率：0.9615

类别4的平均准确率：0.9246

类别5的平均准确率：0.6573

类别6的平均准确率：0.6790

类别7的平均准确率：0.8493

类别8的平均准确率：0.9399

整体平均准确率：0.835261

### 白葡萄酒

#### SVM模型参数

类别9

+ 最大迭代次数：20
+ 正则化系数：0.001
+ 容忍度T：1e-3

类别3

+ 最大迭代次数：50
+ 正则化系数：0.001
+ 容忍度：1e-3

类别4、8

+ 最大迭代次数：100
+ 正则化系数：0.1
+ 容忍度：1e-4

类别7

+ 最大迭代次数：400
+ 正则化系数：0.5
+ 容忍度：1e-4

类别5

+ 最大迭代次数：850
+ 正则化系数：0.5
+ 容忍度：1e-4

类别6:

+ 最大迭代次数：1500
+ 正则化系数：0.5
+ 容忍度：1e-4

#### 准确率

类别3：0.9814

类别4：0.9432

类别5：0.7242

类别6：0.5842

类别7：0.8346

类别8：0.9432

类别9：0.9903

整体平均准确率：0.85711

### **分析**

SVM对中等等级（5~7）的准确率约在65.7% ~ 72.5%。对于极端情况（3、4、8、9级），由于样本数过少，因此要通过SMOTE过采样和设置SVM参数尽可能优化拟合。尽管如此，部分极端类别仍然出现了过拟合的情况。模型的整体准确率是足够高的，对于一般场景，模型是适用的

总体来说，红、白葡萄酒的SVM模型对于类别7的预测效果最好，达到了83.5%~85.0%左右，模型对于类别5、6的预测效果较好，在65.7% ~ 72.5%左右，适合大部分场景的应用











