# 实验二 统计分析

## 实验要求

### 聚类分析

1. 实现K-Means算法，自定义K值对数据集"聚类数据.txt"进行聚类分析，结果导出到HDFS中
2. 使用其他聚类算法，重新对"聚类数据.txt"进行聚类，结果仍然导出到HDFS中

注意：结果的导出格式为：在原数据集中的序号 | 标签（分到了哪一组）

![image-20241020152757930](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/image-20241020152757930.png)

### 分类分析

1. 基于MapReduce框架实现朴素贝叶斯，使用训练数据对模型进行训练，然后对测试数据进行测试，并将测试结果导出至HDFS中
2. 自行选择朴素贝叶斯以外的分类算法，基于MapReduce框架实现，使用训练数据对模型进行训练，然后对测试数据进行测试，并将测试结果导出

注意：分类结果的导出格式与聚类部分相同，每行一个标签，标签为数字格式，标签的顺序与原始数据集中的测试数据的顺序相同

## 数据集概述

+ 聚类
  + 聚类数据.txt：20个属性，用英文逗号分隔开
+ 分类
  + 训练数据.txt：20个属性 + 标签0/1 
  + 验证数据.txt：20个属性 + 标签0/1
  + 测试数据.txt：20个属性，不包含标签

## 聚类分析

**设计实现K-Means和K-Medoide算法**

聚类算法的关键问题：最佳的K值如何选择？如何确定最初的中心点？什么时候停止聚类循环？

+ **最佳的K值如何选择**：聚类数据.txt共有150万条数据，按照经验来说，k最好在1225（即1500000的开方）附近取值，因此将k设置为1225，即聚类得到1225个类
+ **如何确定最初的中心点**：使用**蓄水池抽样**选取k个元素，将结果输出到HDFS中
+ **什么时候停止迭代**：不同的算法要求不一样。对于K-Means，当新旧中心点之间的距离 < 某个阈值时，则认为算法收敛；对于K-Medoide，当中心点不再变化时，则认为算法收敛

### 初始化聚类中心点

使用**蓄水池抽样**选取k个元素

+ Mapper：

  + setup阶段初始化一个存放抽样结果的数据结构begin_center，这将是初始的中心点
  + map阶段执行水库抽样
    + **对于元素 1 到 k**：在水库（`begin_center`）未满的情况下，直接将这些元素加入到水库中。
    + **对于元素 k+1 到 n**：此时水库已满，每个元素的序号为 `x`。这些元素有 **`k/x`** 的概率被选中并加入到水库中，替换掉水库中的某个已有元素，而水库中的每个元素有 **`1/k`** 的概率被替换掉。
  + cleanup阶段将begin_center中包含的记录输出给reducer

+ Reducer：

  由于会有多个Mapper进行水库抽样，则到达Reducer的会有 k*Mapper数量 个记录，则Reducer需要再对到来的记录进行水库抽样，挑选出k个记录输出到HDFS中，这是初始的中心点，将它输出到HDFS文件系统中

  注意：map阶段只是针对每条记录进行筛选，并不会输出结果。水库抽样中，只有所有的记录到来后才能获得抽样的结果。在cleanup阶段输出最终的抽样结果

### K-Means

#### 难点

+ **中间结果**

  K-Means需要迭代更新中心点，每一轮迭代的输入都是上一轮更新后的中心点数据。然而，MapReduce不太适合迭代计算，这是因为MapReduce每次迭代都需要将所有数据写回磁盘，然后再从磁盘读取进入下一个任务，即每次迭代的中间结果无法保存在内存中。K-Means中每轮迭代的中间结果是**更新后的中心点数据**，因此每轮迭代都需要**将中心点数据写到HDFS中**，供下一轮迭代使用

+ **并发执行**

  + **访问数据**：在不同的节点上有多个Mapper任务并发执行，这些Mapper任务 无法共享 Mapper类中定义的数据结构 或 外部类中定义的静态数据结构。原因有2点：
    + **每个 Mapper 运行在独立的 JVM 中，内存隔离**： 在分布式环境中，任务调度框架会为每个 Mapper任务 分配一个独立的 JVM 进程，这些JVM进程的内存空间是完全隔离的，因此一个Mapper任务不会访问其他Mapper任务在Mapper类中的数据结构
    + **外部类的静态变量在每个 JVM 中都有独立的副本**：静态变量的作用域是类加载器级别。分布式环境中，每个节点的 JVM 会独立加载外部类的定义，并在该 JVM 内部初始化自己的静态变量，因此Mapper任务不会共享外部类的静态数据结构
  + **修改数据**：每个Mapper都只能看到全体数据的一部分，这是分片的作用。如果在Mapper中对一些数据进行修改可能会因为处理的局部性而导致对全局数据的修改是错误的。另外，并发的Mapper对同一个文件进行修改，则会相互覆盖，最终只能得到一个Mapper的结果

  伪分布式架构在同一台机器上运行多个 JVM 进程，每个进程负责执行一个任务（Mapper 或 Reducer）。每个 JVM 的内存空间独立，因此Mapper 之间无法共享外部类的静态数据

  全局修改和汇总的任务通常由 Reducer 完成。Reducer也可以有多个，同一个键的所有数据会被发送给同一个Reducer来处理。如果任务需要对全局数据进行统一处理且无法分片，则应该使Reducer只有1个，使所有Mapper到来的数据汇总到一个Reducer中


#### 实现思路

+ **Driver：配置MapReduce作业信息，初始化并广播 上一次迭代更新后的中心点数据**

  在Driver中读取中心点文件，将中心点数据加载到内存中，然后通过Configuration进行广播，即将这些数据序列化并存储到`Configuration`对象中。这样，每个`Mapper`和`Reducer`在执行时都可以通过`Configuration`对象访问这些广播的数据，避免了重复从HDFS中读取数据

+ **Mapper：重新划分类别，输出每个记录和它所属于的类别序号**

  + setup阶段从`Configuration`对象中读取中心点数据，初始化中心点列表centroids（`List<double[]>`）。centroids存储了每个中心点所有字段的数值

  + map阶段的输入是聚类数据集，在map中计算记录与各个中心点之间的欧式距离，将记录划分到距离最小的类别中。

    实验中要求聚类结果集与原始数据集中 记录的顺序是一致的，这需要保证记录被Reducer的处理顺序与其在原始文件中的行号一致，从而让Reducer按照行号顺序将记录的聚类结果输出到上下文，因此Mapper以当前行的偏移量为键，输出<当前行的偏移量，记录所属类别>键值对

    记录所属类别是一个`RecordClusteridWritable`对象，它存储了记录的内容和它的类别序号。注意到Mapper输出的key和value必须是序列化的（MapReduce通过传输序列化的数据实现跨节点的数据传输），因此`RecordCLusteridWritable`对象要实现`Writable`接口，重写`write`和`readFields`方法

+ **Reducer：使用平均值更新每个类别的中心点，以 (行号，记录所属类别) 的形式输出聚类结果**

  + setup阶段从`Configuration`对象中读取中心点数据，初始化中心点列表`centroids`。然后初始化哈希表`clusterMap`，它存储了<类别序号，`ClusterSumNum`对象>键值对，其中`ClusterSumNum`提供方法用于统计每个类别中包含的记录总数`num` 和 所有记录各个列的和`double[] sum`
  + reduce阶段用于更新各个类别的记录数与列和，输出聚类结果。
    + **创建`ClusterSumNum`，统计类别的记录数和记录的列和**：对到来的每一条记录，根据它所属的类别在哈希表`clusterMap`中查找对应的表项，更新表项中的`ClusterSumNum`对象保存的记录数与列和
    + **输出聚类结果**：Mapper 输出时以当前行的偏移量作为键，这确保了记录被 Reducer 处理的顺序与其在原始文件中的行号一致。因此，可以在 Reducer 中使用 `lineNumber` 作为计数器对每条输入记录进行编号，从而生成对应的行号。最终，将<行号, 所属类别> 键值对输出到上下文。为了确保计数器 `lineNumber` 是全局一致的，并正确记录行号，必须限制 Reducer 的数量为 1。如果启用了多个 Reducer，每个 Reducer 的 `lineNumber` 计数器将独立工作，导致行号出现重复或错误的情况
  + cleanup阶段根据哈希表 `clusterMap` 的表项，使用各类点的平均值来更新中心点，并将新的中心点数据写回到中心点文件。更新中心点后，还需要计算更新前后中心点的距离，并与阈值 `delta` 进行比较，以判断算法是否已收敛

若前后中心点的距离 < `delta`，则认为算法已经收敛，可以退出迭代。否则，则需要重复上述步骤继续迭代

### K-Medoide

#### 难点

+ **更新中心点**

  K-Medoide更新中心点的策略是：计算类别中各个记录点与其他记录点之间的距离之和（总体相异度），选取总体相异度最小的记录点为类别的新中心点。在Reducer中需要将同一个类别的所有记录汇聚到同一个Reducer中处理，这样才能计算各个记录点与其他记录点之间的距离之和，因此Mapper阶段输出时，以“记录所属的类别序号”为键，而不是以“当前行的偏移值”为键。这么做能保证同一类别的序号被输入到同一个Reudcer中，但是无法保证记录 在聚类结果数据集 和 在原始数据集 中的顺序是一致的

#### 实现思路

K-Medoide的MapReduce设计过程与K-Means类似，在Driver中读取中心点坐标并保存到对象`Configuration`中，在Mapper中需要根据记录与各个中心点之间的欧氏距离判断记录所属的类别，不同的是Reducer的处理：在Reducer中，对于同一个类别的所有记录，调用`getNewCentroid`计算类别中各个点与其他点的距离之和，寻找距离之和最小的记录点作为类别新的中心点，最终Reducer将<类别序号，记录>输出到上下文

## 分类分析

**设计实现朴素贝叶斯分类器 和 逻辑回归分类器**

每个分类器都需要经过训练、验证、预测过程，分别使用训练数据集、验证数据集、预测数据集作为输入

### 朴素贝叶斯分类器

朴素贝叶斯分类器的原理很简单，以类别$C$在样本中的频率 作为先验概率$P(C)$，以属性 $j$ 在类别 $C$ 中取值为$value$的频率 作为条件概率$P(attribute_j =value|C)$

在验证与预测阶段，对于一条记录$record$，它属于类别$C$的概率为$P(C|record)$。使用贝叶斯公式计算$P(C|record)$：
$$
P(C|record) = \frac{P(record|C) \times P(C)}{P(record)}
$$
朴素贝叶斯做出了条件独立性假设，即在给定类别的条件下，假设属性之间的取值是相互独立的。根据这个假设，$P(record|cluster_i)$的计算公式为：
$$
P(record|C) = P(\text{attribute}_1, \text{attribute}_2, \dots, \text{attribute}_n \mid C) \\= \prod_{i=1}^{n} P(\text{attribute}_i \mid C)
\
$$
比较记录属于各个类别的概率，选择概率最高的类别作为该记录的分类结果。由于记录属于各个类别的概率中$P(record)$是相同的，因此只需要计算$P(record|C) \times P(C)$

#### 训练

为简化模型，在计算条件概率时，仅考虑属性值为正或负的分类特性，即$P(attribute_j = 1| C)$表示在类别$C$中，属性$attribute_j$为正的概率

+ **Mapper：从记录中提取类别和属性的分类信息**

  + map阶段以训练数据集为输入。为了统计类别和属性的信息，创建NavieBayesKey对象作为组合键。NavieBayesKey作为组合键有两种类型：类别键 与 属性键。其中，类别键中存储了类别的ID，属性键中存储了属性所在的类别ID、属性ID、属性值是否为正。通过type来区分组合键的类型。
    + 构造类别键：对于每一条记录，提取出它的类别ID，并创建NavieBayesKey对象存储类别ID，将<NavieBayesKey对象, 1>输出到上下文
    + 构造属性键：对于每一条记录，遍历它的所有属性，为它的每个属性构造属性键，即创建NavieBayesKey对象存储类别ID、属性ID、属性是否为正，将<NavieBayesKey对象, 1>输出到上下文

+ **Reducer：统计类别和属性的信息并输出到训练结果集**

  + setup阶段初始化`classStats`数组用于存储各个类别的数量，初始化`attributeStats`数组用于存储各个属性的信息

  + reduce阶段以Mapper输出的<NavieBayesKey对象, 1>作为输入。reduce需要分别统计类别和属性信息，因此对于属性键和类别键，有不同的处理方法：
    + 处理类别键：从NavieBayesKey对象中提取类别ID，更新`classStats`：`classStats[ID]++`
    + 处理属性键：从NavieBayesKey对象中提取出类别ID、属性ID、属性是否为正的信息，更新`attributeStats`：`attributeStats[类别ID][属性ID][condition]++`，当属性值 > 0时，condition=1
  + cleanup阶段将reduce中统计的类别和属性的信息输出到训练结果集。cleanup阶段只需要按照一定的格式将`classStats`和`attributeStats`中的信息输出到文件中，形成训练结果集

最终的训练结果：

属性信息：

![image-20241220170234752](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/image-20241220170234752.png)

类别信息：

![image-20241220170300764](https://myc-picture.oss-cn-beijing.aliyuncs.com/database/image-20241220170300764.png)

#### 预测与验证

预测与验证的逻辑类似，因此放在一起讲述：

+ **Mapper**：
  + setup阶段从训练结果集中读取先验概率和条件概率
  + map阶段将输入的 `value` 分割成属性值数组。使用 `NaiveBayesPredict` 方法计算该记录属于每个类别的概率，选取概率最大的类别作为预测结果。最终输出 <记录的行号, 预测类别>
+ **Reducer**：
  + reduce阶段，对于预测来说直接输出<记录，预测类别>，对于验证来说需要计算分类结果和标签是否相同，计算模型的准确率

**朴素贝叶斯分类器的准确率为：0.8179666666666667**

### 逻辑回归分类器

#### 训练

+ **Mapper**

  + map阶段将所有输入行标记为键 `"sample"`，确保所有数据被传递到同一个 Reducer

+ **Reducer**

  + setup阶段初始化权重向量 `weights`，每个权重值随机分布在 `[-0.01, 0.01]` 范围内
  + reduce阶段聚合 Mapper 输出的所有样本，并对数据进行多轮迭代，通过 **梯度下降法** 优化权重

  + 梯度下降法优化权重：在每次迭代中，通过计算模型的预测值 `predicted` 和真实标签 `label` 之间的误差 `error` 来计算梯度。梯度是误差与输入特征的乘积：`error * trainSample[j]`。梯度值累加后，更新权重。最后，通过构建一个字符串输出最终的权重向量。使用 `StringBuilder` 格式化输出，并将其作为 Reducer 的输出。
  + Reduceer输出的 `key` 是最终的权重向量。`value` 是空的，表示该输出没有附加的内容，只是纯粹的权重结果

#### 预测与验证

+ **Mapper**
  + map阶段仅将输入的每一行数据原封不动地输出到Reducer，并没有做任何实际的处理
+ **Reducer**
  + setup阶段中Reducer首先从HDFS读取训练好的Logistic回归模型的权重（`weights`）
  + reduce阶段对于每个输入的`Text`值（即一个包含特征数据的字符串），首先将其拆分成一个特征数组（`validationSample`）。使用`PredictClass`方法计算Logistic回归模型的预测概率。根据计算得到的概率，判断预测类别（`predictedClass`），如果概率大于0.5，则预测为类别1，否则预测为类别0。最终将预测类别与行号（`lineNumber`）一起输出。

**逻辑回归分类器的准确率为0.8526566666666667**



















